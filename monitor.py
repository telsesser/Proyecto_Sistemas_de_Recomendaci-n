#!/usr/bin/env python3
"""
Monitor simple para el scraper de GitHub
Uso: python monitor.py [--watch] [--interval 5]
"""

import json
import os
import time
import argparse
import sys
from datetime import datetime


def clear_screen():
    """Limpia la pantalla"""
    os.system("cls" if os.name == "nt" else "clear")


def format_bytes(bytes_val):
    """Convierte bytes a formato legible"""
    for unit in ["B", "KB", "MB", "GB"]:
        if bytes_val < 1024.0:
            return f"{bytes_val:.1f} {unit}"
        bytes_val /= 1024.0
    return f"{bytes_val:.1f} TB"


def get_file_info(filepath):
    """Obtiene info de un archivo parquet"""
    if not os.path.exists(filepath):
        return {"exists": False, "size": 0, "size_str": "0 B", "modified": "N/A"}

    stat = os.stat(filepath)
    size = stat.st_size
    modified = datetime.fromtimestamp(stat.st_mtime).strftime("%H:%M:%S")

    return {
        "exists": True,
        "size": size,
        "size_str": format_bytes(size),
        "modified": modified,
    }


def show_status():
    """Muestra el estado actual del scraper"""
    data_dir = "data"
    status_file = os.path.join(data_dir, "status.json")
    log_file = os.path.join(data_dir, "api_consumer.log")

    # Leer status.json
    if os.path.exists(status_file):
        try:
            with open(status_file, "r") as f:
                status = json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            status = {"error": "No se pudo leer status.json"}
    else:
        status = {"error": "status.json no encontrado"}

    # Info de archivos
    files = {
        "repos": get_file_info(os.path.join(data_dir, "repos.parquet")),
        "stars": get_file_info(os.path.join(data_dir, "stars.parquet")),
        "contributors": get_file_info(os.path.join(data_dir, "contributors.parquet")),
        "forks": get_file_info(os.path.join(data_dir, "forks.parquet")),
        "issues": get_file_info(os.path.join(data_dir, "issues.parquet")),
    }

    # Ãšltimas lÃ­neas del log
    log_lines = []
    if os.path.exists(log_file):
        try:
            with open(log_file, "r", encoding="utf-8") as f:
                log_lines = f.readlines()[-5:]  # Ãšltimas 5 lÃ­neas
        except:
            log_lines = ["Error leyendo log"]

    print("=" * 80)
    print("ðŸ” MONITOR GITHUB SCRAPER")
    print("=" * 80)
    print(f"â° Actualizado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    if "error" in status:
        print(f"âŒ ERROR: {status['error']}")
        print()
    else:
        # Estado general
        print("ðŸ“Š ESTADÃSTICAS GENERALES")
        print("-" * 40)
        print(f"ðŸƒ Runtime:           {status.get('runtime_formatted', 'N/A')}")
        print(f"ðŸ“¦ Repos procesados:  {status.get('repos_processed', 0):,}")
        print(f"ðŸ“„ PÃ¡ginas:           {status.get('pages_processed', 0):,}")
        print(f"ðŸŒ API calls:         {status.get('api_calls', 0):,}")
        print(f"âŒ Errores:           {status.get('errors', 0):,}")
        print(f"â¸ï¸ Rate limits:       {status.get('rate_limits', 0)}")
        print(f"ðŸ“ˆ Repos/hora:        {status.get('avg_repos_per_hour', 0):.1f}")
        print(f"ðŸ“ˆ Calls/minuto:      {status.get('avg_api_calls_per_minute', 0):.1f}")
        print(f"ðŸŽ¯ Ãšltimo repo:       {status.get('last_repo', 'N/A')}")
        print()

        # Datos recolectados
        print("ðŸ—ƒï¸ DATOS RECOLECTADOS")
        print("-" * 40)
        print(f"â­ Stars:            {status.get('stars_fetched', 0):,}")
        print(f"ðŸ‘¥ Contributors:     {status.get('contributors_fetched', 0):,}")
        print(f"ðŸ´ Forks:            {status.get('forks_fetched', 0):,}")
        print(f"ðŸž Issues:           {status.get('issues_fetched', 0):,}")
        print()

    # Archivos
    print("ðŸ“ ARCHIVOS PARQUET")
    print("-" * 40)
    total_size = 0
    for name, info in files.items():
        if info["exists"]:
            print(f"{name:12} â”‚ {info['size_str']:>8} â”‚ {info['modified']}")
            total_size += info["size"]
        else:
            print(f"{name:12} â”‚     N/A  â”‚   N/A")
    print("-" * 40)
    print(f"{'TOTAL':12} â”‚ {format_bytes(total_size):>8} â”‚")
    print()

    # Log reciente
    print("ðŸ“ LOG RECIENTE (Ãºltimas 5 lÃ­neas)")
    print("-" * 60)
    if log_lines:
        for line in log_lines:
            # Limpiar y truncar lÃ­neas muy largas
            clean_line = line.strip()
            if len(clean_line) > 75:
                clean_line = clean_line[:72] + "..."
            print(clean_line)
    else:
        print("No hay logs disponibles")

    print("=" * 80)


def monitor_loop(interval):
    """Loop de monitoreo continuo"""
    try:
        while True:
            clear_screen()
            show_status()
            print(f"\nðŸ”„ Actualizando cada {interval} segundos... (Ctrl+C para salir)")
            time.sleep(interval)
    except KeyboardInterrupt:
        print("\nðŸ‘‹ Monitor detenido")
        sys.exit(0)


def main():
    parser = argparse.ArgumentParser(description="Monitor para GitHub scraper")
    parser.add_argument(
        "--watch", "-w", action="store_true", help="Modo watch continuo"
    )
    parser.add_argument(
        "--interval",
        "-i",
        type=int,
        default=5,
        help="Intervalo en segundos para --watch (default: 5)",
    )

    args = parser.parse_args()

    if args.watch:
        monitor_loop(args.interval)
    else:
        show_status()


if __name__ == "__main__":
    main()
